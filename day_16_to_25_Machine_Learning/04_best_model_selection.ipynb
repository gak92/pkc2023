{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# other libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']]\n",
    "y = df['survived']\n",
    "\n",
    "X = pd.get_dummies(X, columns=['sex'])  # one-hot encoding\n",
    "X['age'] = X['age'].fillna(X['age'].mean())  # fill missing values with mean age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "age           0\n",
       "sibsp         0\n",
       "parch         0\n",
       "fare          0\n",
       "sex_female    0\n",
       "sex_male      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()  # check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (712, 7)\n",
      "X_test shape:  (179, 7)\n",
      "y_train shape:  (712,)\n",
      "y_test shape:  (179,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best model\n",
    "\n",
    "models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), KNeighborsClassifier()]\n",
    "model_names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'KNN']\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append([model_name, accuracy])\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    precision_scores.append([model_name, precision])\n",
    "\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    recall_scores.append([model_name, recall])\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_scores.append([model_name, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_scores(scores):\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  Logistic Regression : 0.81\n",
      "Accuracy Score:  Random Forest : 0.81\n",
      "Accuracy Score:  Decision Tree : 0.75\n",
      "Accuracy Score:  KNN : 0.69\n",
      "Accuracy Score:  SVM : 0.66\n"
     ]
    }
   ],
   "source": [
    "# print accuracy Scores\n",
    "for model in sorted_scores(accuracy_scores):\n",
    "    print(\"Accuracy Score: \", f'{model[0]} : {model[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  Logistic Regression : 0.80\n",
      "Precision Score:  Random Forest : 0.79\n",
      "Precision Score:  SVM : 0.76\n",
      "Precision Score:  Decision Tree : 0.71\n",
      "Precision Score:  KNN : 0.65\n"
     ]
    }
   ],
   "source": [
    "# print precision Scores\n",
    "for model in sorted_scores(precision_scores):\n",
    "    print(\"Precision Score: \", f'{model[0]} : {model[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score:  Random Forest : 0.74\n",
      "Recall Score:  Logistic Regression : 0.72\n",
      "Recall Score:  Decision Tree : 0.68\n",
      "Recall Score:  KNN : 0.54\n",
      "Recall Score:  SVM : 0.26\n"
     ]
    }
   ],
   "source": [
    "# print recall Scores\n",
    "for model in sorted_scores(recall_scores):\n",
    "    print(\"Recall Score: \", f'{model[0]} : {model[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  Random Forest : 0.76\n",
      "F1 Score:  Logistic Regression : 0.76\n",
      "F1 Score:  Decision Tree : 0.69\n",
      "F1 Score:  KNN : 0.59\n",
      "F1 Score:  SVM : 0.38\n"
     ]
    }
   ],
   "source": [
    "# print f1 scores\n",
    "for model in sorted_scores(f1_scores):\n",
    "    print(\"F1 Score: \", f'{model[0]} : {model[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Logistic Regression', 0.8100558659217877], ['Decision Tree', 0.7541899441340782], ['Random Forest', 0.8100558659217877], ['SVM', 0.659217877094972], ['KNN', 0.6871508379888268]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.383838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.810056   0.803030  0.716216  0.757143\n",
       "1        Decision Tree  0.754190   0.714286  0.675676  0.694444\n",
       "2        Random Forest  0.810056   0.785714  0.743243  0.763889\n",
       "3                  SVM  0.659218   0.760000  0.256757  0.383838\n",
       "4                  KNN  0.687151   0.645161  0.540541  0.588235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data frame from above lists\n",
    "accuracy_df = pd.DataFrame(accuracy_scores, columns=['Model', 'Accuracy'])\n",
    "precision_df = pd.DataFrame(precision_scores, columns=['Model', 'Precision'])\n",
    "recall_df = pd.DataFrame(recall_scores, columns=['Model', 'Recall'])\n",
    "f1_df = pd.DataFrame(f1_scores, columns=['Model', 'F1'])\n",
    "\n",
    "# combine all dataframes\n",
    "df = pd.merge(accuracy_df, precision_df, on='Model')\n",
    "df = pd.merge(df, recall_df, on='Model')\n",
    "df = pd.merge(df, f1_df, on='Model')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
